<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Arnold on Shih-Chin</title>
    <link>http://shihchinw.github.io/tags/arnold.html</link>
    <description>Recent content in Arnold on Shih-Chin</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Copyright Â© Shih-Chin</copyright>
    <lastBuildDate>Fri, 25 Dec 2015 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="http://shihchinw.github.io/tags/arnold/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Realistic Human Skin with Normalized Diffusion &amp; GGX</title>
      <link>http://shihchinw.github.io/2015/12/realistic-human-skin-with-normalized-diffusion-ggx.html</link>
      <pubDate>Fri, 25 Dec 2015 00:00:00 +0000</pubDate>
      
      <guid>http://shihchinw.github.io/2015/12/realistic-human-skin-with-normalized-diffusion-ggx.html</guid>
      <description>After implementing BSSRDF importance sampling for Normalized Diffusion and GGX BRDF, I started wondering how realistic could the appearance of human skin be achieved with the combination of these two models. The whole development process is quite interesting, because it&amp;rsquo;s a perfect combination of my two interests: programming and photography. With only one diffusion layer and two specular layers on top, I tried to find the way to make it as realistic as possible.</description>
    </item>
    
    <item>
      <title>BSSRDF Importance Sampling of Normalized Diffusion</title>
      <link>http://shihchinw.github.io/2015/10/bssrdf-importance-sampling-of-normalized-diffusion.html</link>
      <pubDate>Tue, 27 Oct 2015 00:00:00 +0000</pubDate>
      
      <guid>http://shihchinw.github.io/2015/10/bssrdf-importance-sampling-of-normalized-diffusion.html</guid>
      <description>Highly scattering materials like milk or skin can&amp;rsquo;t be precisely modeled by BRDF only, because light would scatter multiple times before exiting the material at different locations. Bidirectional surface scattering distribution function (BSSRDF) is used to describe radiance transfer across the surface boundary with diffusion profile for multiple scattering events.
To solve subsurface light transport efficiently, there are several approaches to model and evaluate the diffusion profile. Recently, Burley [5] has proposed an artist-friendly diffusion profile with only two exponential functions and the most attracting thing is that it&amp;rsquo;s not only intuitive for artists to use but also faster to evaluate.</description>
    </item>
    
    <item>
      <title>Using Min Pixel Width with Care in Arnold</title>
      <link>http://shihchinw.github.io/2015/09/using-min-pixel-width-with-care-in-arnold.html</link>
      <pubDate>Thu, 24 Sep 2015 00:00:00 +0000</pubDate>
      
      <guid>http://shihchinw.github.io/2015/09/using-min-pixel-width-with-care-in-arnold.html</guid>
      <description>Keeping objects opaque makes Arnold render much faster. When we render a bunch of hairs, min pixel width is useful to make the hair look softer. However, if the min pixel width is not equal to zero, the opacity of hair ribbon would change subtly, and those ribbons are not always opaque anymore! Furthermore, according to the ribbon thickness measured in screen space at render time, we might surprisedly get different render results.</description>
    </item>
    
    <item>
      <title>Sampling Visible Normals for GGX BRDF</title>
      <link>http://shihchinw.github.io/2015/08/sampling-visible-normals-for-ggx-brdf.html</link>
      <pubDate>Sun, 23 Aug 2015 22:49:00 +0000</pubDate>
      
      <guid>http://shihchinw.github.io/2015/08/sampling-visible-normals-for-ggx-brdf.html</guid>
      <description>The standard approach proposed by Walter et al. [1] for importance sampling of GGX BRDF is to use the PDF proportional to distribution of microfacet normal \(D(\omega)\). However, \(D(\omega)\) is not view-dependent, thus it would waste lots of samples when the incoming direction is near grazing angles. In addition, the small value of \(D(\omega)\vert m\cdot n\vert\) at grazing angle would make the sample value as high as hundreds to millions in some situations and cause fireflies in render results.</description>
    </item>
    
    <item>
      <title>Implementing Disney Principled BRDF in Arnold</title>
      <link>http://shihchinw.github.io/2015/07/implementing-disney-principled-brdf-in-arnold.html</link>
      <pubDate>Sun, 19 Jul 2015 16:05:00 +0000</pubDate>
      
      <guid>http://shihchinw.github.io/2015/07/implementing-disney-principled-brdf-in-arnold.html</guid>
      <description>Disney &amp;ldquo;principled&amp;rdquo; BRDF [1] is a very interesting shading model. It can achieve various physically plausible appearances with only one color parameter and ten scalar parameters! This shading model is designed not only to catch most of the measured data from MERL, but also to follow the principles below:
  Intuitive rather than physical. As few parameters as possible. Parameters are zero to one over their plausible range. Parameters are allowed to be pushed beyond their plausible range where it makes sense.</description>
    </item>
    
    <item>
      <title>Implementing GGX BRDF in Arnold with Multiple Importance Sampling</title>
      <link>http://shihchinw.github.io/2015/06/implementing-ggx-brdf-in-arnold-with-multiple-importance-sampling.html</link>
      <pubDate>Sun, 28 Jun 2015 15:20:00 +0000</pubDate>
      
      <guid>http://shihchinw.github.io/2015/06/implementing-ggx-brdf-in-arnold-with-multiple-importance-sampling.html</guid>
      <description>Monte Carlo path tracing has a slow convergence rate close to \(O(1/\sqrt n)\), it needs to quadruple the number of samples to halve the error. Many mainstream production renderers have deployed multiple importance sampling (MIS) technique to reduce the variance of sampling result (i.e. the noise in image). If we want to make our custom material shader efficiently executed along with the entire render scene in Arnold, we shall definitely consider exploiting the power of MIS.</description>
    </item>
    
    <item>
      <title>Render Tips for Arnold in Maya</title>
      <link>http://shihchinw.github.io/2015/02/render-tips-for-arnold-in-maya.html</link>
      <pubDate>Sun, 22 Feb 2015 16:39:00 +0000</pubDate>
      
      <guid>http://shihchinw.github.io/2015/02/render-tips-for-arnold-in-maya.html</guid>
      <description>&lt;p&gt;All photo-realistic ray-tracers are trying to solve the &lt;a href=&#34;http://www.wired.com/2010/07/st_equation_3danimation/&#34;&gt;rendering equation&lt;/a&gt;. Although they are all categorized as ray-tracer instead of rasterizer, the infrastructure of each implementations are quite different (i.e. uni-directional vs. bi-directional, pure path tracing vs. works with photon-map or &lt;a href=&#34;http://cgg.mff.cuni.cz/~jaroslav/papers/2008-irradiance_caching_class/&#34;&gt;irradiance caching&lt;/a&gt;, etc).&lt;/p&gt;

&lt;p&gt;Arnold is an &lt;em&gt;un-bias uni-directional path tracer&lt;/em&gt; with a remarkable importance sampling mechanism and great memory management to achieve amazing performance excellence. However, if we blindly increase the number of ray samples for every render scene, we would not always get a cleaner imagery. Which means that when we switch from one ray-tracer to another, we had better use different strategies to adjust render settings. Here is the summary about what I&amp;rsquo;ve learned from experience, hope it would help any Arnold user. :)
&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>