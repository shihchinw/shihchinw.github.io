<!doctype html><html lang=en-us><head><meta name=generator content="Hugo 0.121.2"><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content><meta name=author content><title>Shih-Chin</title>
<link rel=alternate type=application/rss+xml href=https://shihchinw.github.io/index.xml title=Shih-Chin><link href=https://shihchinw.github.io/css/bootstrap.css rel=stylesheet><link href=https://shihchinw.github.io/css/clean-blog.css rel=stylesheet><link href=//maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css rel=stylesheet type=text/css><link href='//fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel=stylesheet type=text/css><link href='//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel=stylesheet type=text/css><link href='//fonts.googleapis.com/css?family=Lato:400,400italic|Open+Sans:400italic,600italic,400,600|Coda:800)' media=screen rel=stylesheet type=text/css><script src=https://cdn.rawgit.com/google/code-prettify/master/loader/run_prettify.js></script><link rel=stylesheet href=https://shihchinw.github.io/css/prettyprint.css><link rel=stylesheet href=https://shihchinw.github.io/css/lightbox.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css integrity=sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0 crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js integrity=sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body)})</script><link rel=stylesheet type=text/css href=https://shihchinw.github.io/css/foundation.css><link rel=stylesheet type=text/css href=https://shihchinw.github.io/css/twentytwenty.css><link rel=stylesheet type=text/css href=https://shihchinw.github.io/css/header-anchor.css><link rel="shortcut icon" type=image/png href=https://shihchinw.github.io/favicon.png><style>.katex{font-size:1.1em!important}.intro-header .overlay{background:rgba(0,0,0,.47);z-index:1;width:100%;height:100%;top:0}p+ul{margin-top:-24px}p+ol{margin-top:-24px}h1+p,h2+p,h3+p{margin-top:15px}.summary-content{text-align:justify;margin:5px 0}a.read-more-link{color:#f44336;font-weight:bolder;margin-left:5px}code>div>.table{margin-bottom:0;padding:0}code>div>.table>tbody>tr>td{border-top:none;padding:0}.container .img-responsive{padding:5px;margin:auto;-moz-box-shadow:0 0 5px rgba(0,0,0,.15);-webkit-box-shadow:0 0 5px rgba(0,0,0,.15);box-shadow:0 0 5px rgba(0,0,0,.15);-moz-border-radius:5px;-webkit-border-radius:5px;border-radius:5px;margin-top:10px;margin-bottom:10px}.twentytwenty-container .img-responsive{padding:0;margin:0 auto;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none;border-radius:0}.figure .img-responsive{padding:0;margin:auto;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none;border-radius:0;margin-top:0;margin-bottom:5px}.figure{padding:5px;margin:auto;-moz-box-shadow:0 0 10px rgba(0,0,0,.2);-webkit-box-shadow:0 0 10px rgba(0,0,0,.2);box-shadow:0 0 10px rgba(0,0,0,.2);-moz-border-radius:5px;-webkit-border-radius:5px;border-radius:5px;margin-top:15px;margin-bottom:15px;display:table}figure figcaption{text-align:center;font-size:14px;color:gray}.container li a{text-decoration:underline}.container a:hover,a:focus{background:#a6dcf3;text-decoration:none}samp{display:block;background-color:#003700;font-size:.8em;text-align:left;color:#0f0;padding:5px;white-space:pre-wrap;border-radius:5px;margin:10px 0}samp.error{color:red}blockquote p:first-child,blockquote ul:first-child,blockquote ol:first-child{margin-top:0}.container blockquote{background:#fff1e5;padding:8px;margin-top:20px;margin-bottom:20px;text-align:justify;line-height:1.5;border:dashed;border-color:#e4c9c4}.container blockquote.feedback{white-space:pre-wrap}blockquote time{font-size:80%}blockquote{color:#806565}blockquote a{color:#337ab7}span.blue{border-bottom:1px solid #a6dcf3;box-shadow:inset 0 -6px #a6dcf3}span.orange{border-bottom:1px solid #ffd18c;box-shadow:inset 0 -6px #ffd699}span.red{color:#dc1111}span.green{border-bottom:1px solid #cdf9bb;box-shadow:inset 0 -6px #cdf9bb}.tag-box{list-style:none;margin:0;padding:4px 0;overflow:hidden}.tag-box.inline li{float:left}.tag-box li{padding:4px 6px;margin:2px;background-color:#e6e6e6;-webkit-border-radius:4px;-moz-border-radius:4px;border-radius:4px}.tag-box li a{text-decoration:none}</style></head><body onload=PR.prettyPrint()><nav class="navbar navbar-default navbar-custom navbar-fixed-top"><div class=container-fluid><div class="navbar-header page-scroll"><button type=button class=navbar-toggle data-toggle=collapse data-target=#bs-example-navbar-collapse-1>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span>
</button>
<a class=navbar-brand href=https://shihchinw.github.io>Shih-Chin</a></div><div class="collapse navbar-collapse" id=bs-example-navbar-collapse-1><ul class="nav navbar-nav navbar-right"><li><a href=https://shihchinw.github.io/>home</a></li><li><a href=https://shihchinw.github.io/page/computer-graphics.html>Computer Graphics</a></li><li><a href=https://shihchinw.github.io/page/global-illumination.html>Global Illumination</a></li><li><a href=https://shihchinw.github.io/page/arnold.html>Arnold</a></li><li><a href=https://shihchinw.github.io/page/maya.html>Maya</a></li><li><a href=https://shihchinw.github.io/post.html>Posts</a></li><li><a href=https://shihchinw.github.io/about.html>About</a></li></ul></div></div></nav><header class=intro-header style=background-image:url(https://shihchinw.github.io/images/header/index.jpg)><div class=overlay><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class=site-heading><h1>Shih-Chin</h1><hr class=small><span class=subheading>Study Notes about Computer Graphics</span></div></div></div></div></div></header><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class=post-preview><a href=https://shihchinw.github.io/2019/03/performance-tips-of-numpy-ndarray.html><h2 class=post-title>Performance Tips of NumPy ndarray</h2></a><div class=post-meta>Posted by Shih-Chin on Sun, Mar 17, 2019</div><h3 class=post-subtitle></h3><a href=https://shihchinw.github.io/2019/03/performance-tips-of-numpy-ndarray.html><img src=https://shihchinw.github.io/images/numpy/numpy_L2_perf_cmp_wide_y.png class=img-responsive></a><div class=summary-content><p>When I did homework assignments of the famous Deep Learning course <a href=http://cs231n.stanford.edu/>CS231n</a> from Stanford, I was so impressed by <strong>100X↑</strong> performance boost by using <em>broadcasting</em> mechanism in NumPy. However, broadcasting doesn&rsquo;t always speed up computation, we should also take into account <em>memory usage</em> and <em>memory access pattern</em> [<a href=#ref.2>2</a>], or we will get a slower execution instead. This post shows several experiments and my reasoning of why certain operation is performant or not.</p><a class=read-more-link href=https://shihchinw.github.io/2019/03/performance-tips-of-numpy-ndarray.html>» read more »</a></div><small><span class="fa-stack fa-sm"><i class="fa fa-tags fa-stack-1x"></i></span></small>
<small><a href=https://shihchinw.github.io/tags/python>Python</a></small>
<small>, <a href=https://shihchinw.github.io/tags/numpy>NumPy</a></small></div><hr><div class=post-preview><a href=https://shihchinw.github.io/2018/11/maya-scripting-primer.html><h2 class=post-title>Maya Scripting Primer</h2></a><div class=post-meta>Posted by Shih-Chin on Mon, Nov 12, 2018</div><h3 class=post-subtitle></h3><div class=summary-content><p>For many of my artist colleagues who want to learn scripting in Maya, one of their motivations is mostly to automate repetitive or time-consuming manual tasks. Since Maya can show all command history of our user interactions in Script Editor. Therefore, if we know how to perform target instructions manually, we could write a script of all corresponding commands. But finding the equivalent commands is not straightforward in some situations. Besides looking up documentation, we need other strategies.</p><a class=read-more-link href=https://shihchinw.github.io/2018/11/maya-scripting-primer.html>» read more »</a></div><small><span class="fa-stack fa-sm"><i class="fa fa-tags fa-stack-1x"></i></span></small>
<small><a href=https://shihchinw.github.io/tags/maya-api>Maya API</a></small></div><hr><div class=post-preview><a href=https://shihchinw.github.io/2018/10/data-interpolation-with-radial-basis-functions-rbfs.html><h2 class=post-title>Data Interpolation with Radial Basis Functions (RBFs)</h2></a><div class=post-meta>Posted by Shih-Chin on Tue, Oct 30, 2018</div><h3 class=post-subtitle></h3><a href=https://shihchinw.github.io/2018/10/data-interpolation-with-radial-basis-functions-rbfs.html><img src=https://shihchinw.github.io/images/math/rbf_with_various_kernels.png class=img-responsive></a><div class=summary-content><p>Radial Basis Functions (RBFs) is one of the commonly used methods to interpolate multi-dimensional data. RBFs creates smooth and less oscillating interpolation than inverse distance weighting (IDW) does. It has many applications in Computer Graphics, such as surface reconstruction [<a href=#ref.3>3</a>], animation blending [<a href=#ref.1>1</a>], facial retargeting, color calibration [<a href=#ref.4>4</a>], and etc. Despite of the variety of its applications, those applications all have a common theme called <em>scattered data interpolation</em>.</p><a class=read-more-link href=https://shihchinw.github.io/2018/10/data-interpolation-with-radial-basis-functions-rbfs.html>» read more »</a></div><small><span class="fa-stack fa-sm"><i class="fa fa-tags fa-stack-1x"></i></span></small>
<small><a href=https://shihchinw.github.io/tags/math>Math</a></small></div><hr><div class=post-preview><a href=https://shihchinw.github.io/2018/08/aperture-f-number.html><h2 class=post-title>Aperture & f-number</h2></a><div class=post-meta>Posted by Shih-Chin on Fri, Aug 10, 2018</div><h3 class=post-subtitle></h3><a href=https://shihchinw.github.io/2018/08/aperture-f-number.html><img src=https://shihchinw.github.io/images/rendering/scene_radiance_to_image_irradiance.png class=img-responsive></a><div class=summary-content><p>I have been using DSLR for over 10 years, I thought I knew few knowledge about photography. But after I watched a wonderful online course of digital photography by Prof. Marc Levoy [<a href=#ref.1>1</a>], I just found there were so many details I weren&rsquo;t aware before. The thing embarrassed me the most was that I incorrectly related f-number to lens aperture size. This post is trying to introduce the idea of f-number starting from scene radiance.</p><a class=read-more-link href=https://shihchinw.github.io/2018/08/aperture-f-number.html>» read more »</a></div><small><span class="fa-stack fa-sm"><i class="fa fa-tags fa-stack-1x"></i></span></small>
<small><a href=https://shihchinw.github.io/tags/photography>Photography</a></small>
<small>, <a href=https://shihchinw.github.io/tags/pbr>PBR</a></small></div><hr><div class=post-preview><a href=https://shihchinw.github.io/2017/01/self-study-tips.html><h2 class=post-title>Self-Study Tips</h2></a><div class=post-meta>Posted by Shih-Chin on Tue, Jan 24, 2017</div><h3 class=post-subtitle></h3><a href=https://shihchinw.github.io/2017/01/self-study-tips.html><img src=https://shihchinw.github.io/images/self-study/study_workflow.jpg class=img-responsive></a><div class=summary-content><p>When I decided to be a guest lecturer at NCKU last year, I kept asking myself what is the most important thing I wish I&rsquo;d learned in school. I carefully reviewed my current skill sets and found most of my skills were developed at work. Besides sharing knowledge about Computer Graphics, I think there is a more fundamental competency we need to develop in school, that is <span class=green><strong>continuous learning</strong></span>.</p><a class=read-more-link href=https://shihchinw.github.io/2017/01/self-study-tips.html>» read more »</a></div><small><span class="fa-stack fa-sm"><i class="fa fa-tags fa-stack-1x"></i></span></small>
<small><a href=https://shihchinw.github.io/tags/study>Study</a></small></div><hr><div class=post-preview><a href=https://shihchinw.github.io/2016/12/learning-by-teaching-as-a-guest-lecturer.html><h2 class=post-title>Learning by Teaching, as a Guest Lecturer</h2></a><div class=post-meta>Posted by Shih-Chin on Sat, Dec 31, 2016</div><h3 class=post-subtitle></h3><div class=summary-content><p>I was privileged to be a guest lecturer to give five lectures about Computer Graphics at National Cheng Kung University (NCKU) in Taiwan. When I prepared the course materials, I deeply realized again that the best way to learn a topic is to teach someone else (especially to a person who never heard about Computer Graphics before). In order to avoid teaching wrong ideas, I had carefully reviewed what I known from ground up and derived each mathematical equation in the textbooks. This post is about what I&rsquo;ve learned in those few months.</p><a class=read-more-link href=https://shihchinw.github.io/2016/12/learning-by-teaching-as-a-guest-lecturer.html>» read more »</a></div><small><span class="fa-stack fa-sm"><i class="fa fa-tags fa-stack-1x"></i></span></small>
<small><a href=https://shihchinw.github.io/tags/study>Study</a></small></div><hr><div class=post-preview><a href=https://shihchinw.github.io/2015/12/realistic-human-skin-with-normalized-diffusion-ggx.html><h2 class=post-title>Realistic Human Skin with Normalized Diffusion & GGX</h2></a><div class=post-meta>Posted by Shih-Chin on Fri, Dec 25, 2015</div><h3 class=post-subtitle></h3><a href=https://shihchinw.github.io/2015/12/realistic-human-skin-with-normalized-diffusion-ggx.html><img src=https://shihchinw.github.io/images/rlShaders/rlSkin_inf_head_uffizi.jpg class=img-responsive></a><div class=summary-content>After implementing BSSRDF importance sampling for Normalized Diffusion and GGX BRDF, I started wondering how realistic could the appearance of human skin be achieved with the combination of these two models. The whole development process is quite interesting, because it&rsquo;s a perfect combination of my two interests: programming and photography. With only one diffusion layer and two specular layers on top, I tried to find the way to make it as realistic as possible.
<a class=read-more-link href=https://shihchinw.github.io/2015/12/realistic-human-skin-with-normalized-diffusion-ggx.html>» read more »</a></div><small><span class="fa-stack fa-sm"><i class="fa fa-tags fa-stack-1x"></i></span></small>
<small><a href=https://shihchinw.github.io/tags/arnold>Arnold</a></small>
<small>, <a href=https://shihchinw.github.io/tags/bssrdf>BSSRDF</a></small></div><hr><div class=post-preview><a href=https://shihchinw.github.io/2015/10/bssrdf-importance-sampling-of-normalized-diffusion.html><h2 class=post-title>BSSRDF Importance Sampling of Normalized Diffusion</h2></a><div class=post-meta>Posted by Shih-Chin on Tue, Oct 27, 2015</div><h3 class=post-subtitle></h3><a href=https://shihchinw.github.io/2015/10/bssrdf-importance-sampling-of-normalized-diffusion.html><img src=https://shihchinw.github.io/images/rlShaders/rlSssNd_buddha.jpg class=img-responsive></a><div class=summary-content>Highly scattering materials like milk or skin can&rsquo;t be precisely modeled by BRDF only, because light would scatter multiple times before exiting the material at different locations. Bidirectional surface scattering distribution function (BSSRDF) is used to describe radiance transfer across the surface boundary with diffusion profile for multiple scattering events.
To solve subsurface light transport efficiently, there are several approaches to model and evaluate the diffusion profile. Recently, Burley [5] has proposed an artist-friendly diffusion profile with only two exponential functions and the most attracting thing is that it&rsquo;s not only intuitive for artists to use but also faster to evaluate.
<a class=read-more-link href=https://shihchinw.github.io/2015/10/bssrdf-importance-sampling-of-normalized-diffusion.html>» read more »</a></div><small><span class="fa-stack fa-sm"><i class="fa fa-tags fa-stack-1x"></i></span></small>
<small><a href=https://shihchinw.github.io/tags/arnold>Arnold</a></small>
<small>, <a href=https://shihchinw.github.io/tags/bssrdf>BSSRDF</a></small>
<small>, <a href=https://shihchinw.github.io/tags/importance-sampling>Importance Sampling</a></small></div><hr><div class=post-preview><a href=https://shihchinw.github.io/2015/09/using-min-pixel-width-with-care-in-arnold.html><h2 class=post-title>Using Min Pixel Width with Care in Arnold</h2></a><div class=post-meta>Posted by Shih-Chin on Thu, Sep 24, 2015</div><h3 class=post-subtitle></h3><a href=https://shihchinw.github.io/2015/09/using-min-pixel-width-with-care-in-arnold.html><img src=https://shihchinw.github.io/images/arnold/mtoa_hair_mpw_opaque_cmp_1k.jpg class=img-responsive></a><div class=summary-content>Keeping objects opaque makes Arnold render much faster. When we render a bunch of hairs, min pixel width is useful to make the hair look softer. However, if the min pixel width is not equal to zero, the opacity of hair ribbon would change subtly, and those ribbons are not always opaque anymore! Furthermore, according to the ribbon thickness measured in screen space at render time, we might surprisedly get different render results.
<a class=read-more-link href=https://shihchinw.github.io/2015/09/using-min-pixel-width-with-care-in-arnold.html>» read more »</a></div><small><span class="fa-stack fa-sm"><i class="fa fa-tags fa-stack-1x"></i></span></small>
<small><a href=https://shihchinw.github.io/tags/arnold>Arnold</a></small></div><hr><div class=post-preview><a href=https://shihchinw.github.io/2015/08/sampling-visible-normals-for-ggx-brdf.html><h2 class=post-title>Sampling Visible Normals for GGX BRDF</h2></a><div class=post-meta>Posted by Shih-Chin on Sun, Aug 23, 2015</div><h3 class=post-subtitle></h3><a href=https://shihchinw.github.io/2015/08/sampling-visible-normals-for-ggx-brdf.html><img src=https://shihchinw.github.io/images/rlShaders/ggx_sampling_comparison.jpg class=img-responsive></a><div class=summary-content>The standard approach proposed by Walter et al. [1] for importance sampling of GGX BRDF is to use the PDF proportional to distribution of microfacet normal \(D(\omega)\). However, \(D(\omega)\) is not view-dependent, thus it would waste lots of samples when the incoming direction is near grazing angles. In addition, the small value of \(D(\omega)\vert m\cdot n\vert\) at grazing angle would make the sample value as high as hundreds to millions in some situations and cause fireflies in render results.
<a class=read-more-link href=https://shihchinw.github.io/2015/08/sampling-visible-normals-for-ggx-brdf.html>» read more »</a></div><small><span class="fa-stack fa-sm"><i class="fa fa-tags fa-stack-1x"></i></span></small>
<small><a href=https://shihchinw.github.io/tags/arnold>Arnold</a></small>
<small>, <a href=https://shihchinw.github.io/tags/brdf>BRDF</a></small>
<small>, <a href=https://shihchinw.github.io/tags/importance-sampling>Importance Sampling</a></small></div><hr><ul class=pager><li class=next><a href=https://shihchinw.github.io/page/2.html class=next>Older Posts &rarr;</a></li></ul></div></div></div><hr><footer><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center"><li><a href=mailto:shihchin.weng@gmail.com><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i>
<i class="fa fa-envelope-o fa-stack-1x fa-inverse"></i></span></a></li><li><a href=https://twitter.com/shihchinw><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i>
<i class="fa fa-twitter fa-stack-1x fa-inverse"></i></span></a></li><li><a href=https://github.com/shihchinw><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i>
<i class="fa fa-github fa-stack-1x fa-inverse"></i></span></a></li></ul><p class="copyright text-muted">Copyright © Shih-Chin</p></div></div></div></footer><script src=https://shihchinw.github.io/js/jquery.min.js></script><script src=https://shihchinw.github.io/js/bootstrap.min.js></script><script src=https://shihchinw.github.io/js/clean-blog.js></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-L4ZM8YZ5G6"></script><script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-L4ZM8YZ5G6",{anonymize_ip:!1})}</script><script src=https://shihchinw.github.io/js/lightbox.js></script><script src=https://shihchinw.github.io/js/jquery.event.move.js></script><script src=https://shihchinw.github.io/js/jquery.twentytwenty.js></script><script>$(window).load(function(){$(".twentytwenty-container[data-orientation!='vertical']").twentytwenty({default_offset_pct:.7}),$(".twentytwenty-container[data-orientation='vertical']").twentytwenty({default_offset_pct:.3,orientation:"vertical"})}),$(function(){return $("h1, h2, h3, h4, h5, h6").each(function(e,t){var n=$(t),s=n.attr("id"),o='<i class="fa fa-link"></i>';if(s)return n.append($("<a />").addClass("header-link").attr("href","#"+s).html(o))})})</script></body></html>